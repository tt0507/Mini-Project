{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suited for classification of complex small or medium sized datasets.\n",
    "\n",
    "https://towardsdatascience.com/svm-implementation-from-scratch-python-2db2fc52e5c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# for testing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C = 1.0, n_epochs = 500, learning_rate = 0.1, fitted = False, cost_threshold = 0.01):\n",
    "        self.C = C\n",
    "        self.n_epochs = n_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.fitted = fitted\n",
    "        self.cost_threshold = cost_threshold\n",
    "        \n",
    "        \n",
    "    def cost(self, weights, X, y):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        N = X.shape[0]\n",
    "        \n",
    "        # calculate hinge loss\n",
    "        distances = 1 - Y * (np.dot(X, weights))\n",
    "        distances[distances<0] = 0  # since max(0, distance) in cost function\n",
    "        hinge_loss = self.C * (np.sum(distances)/N)\n",
    "        \n",
    "        # calculate loss\n",
    "        cost = (1/2) * np.dot(weights, weights) + hinge_loss\n",
    "        return cost\n",
    "    \n",
    "    \n",
    "    def cost_gradient(self, weights, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if type(y_batch) == np.float64:\n",
    "            y_batch = np.array([y_batch])\n",
    "            X_batch = np.array([X_batch])\n",
    "            \n",
    "        distance = 1 - (y_batch * np.dot(X_batch, weights))\n",
    "        dw = np.zeros(len(self.weights))\n",
    "        \n",
    "        # for stochastic gradient descent\n",
    "        if max(0, distance) == 0:\n",
    "            di = weights\n",
    "        else:\n",
    "            di = weights - (self.C * y_batch * X_batch)\n",
    "        dw += di\n",
    "        \n",
    "#         for index, dist in enumerate([distance]):\n",
    "#             if max(0, dist) == 0:\n",
    "#                 di = weights\n",
    "#             else:\n",
    "#                 di = weights - (self.C * [y_batch][index] * [X_batch][index])\n",
    "#             dw += di\n",
    "#         dw = dw/len([y_batch]) \n",
    "\n",
    "        return dw\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit SVM using Stochastic Gradient Descent\n",
    "        \"\"\"\n",
    "        self.fitted = True  # check if fit method has been called\n",
    "        self.weights = np.zeros(X_train.shape[1])  # initialize weight\n",
    "        prev_cost = 0\n",
    "        \n",
    "        for epochs in range(1, self.n_epochs):\n",
    "            X, Y = shuffle(X_train, y_train)\n",
    "            \n",
    "            for index, x in enumerate(X):\n",
    "                ascend = self.cost_gradient(self.weights, x, Y[index])\n",
    "                self.weights = self.weights - (self.learning_rate * ascend)\n",
    "#                 print(self.weights)\n",
    "                \n",
    "                cost = self.cost(self.weights, x, Y[index])\n",
    "                if abs(prev_cost - cost) < self.cost_threshold * prev_cost:\n",
    "                    return self.weights\n",
    "#             break    \n",
    "                \n",
    "        return self.weights\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.fitted == False:\n",
    "            raise Exception('fit method has not be called')\n",
    "            \n",
    "        y_predicted = np.array([])\n",
    "        \n",
    "        for i in range(X_test.shape[0]):\n",
    "            y_predict_value = np.sign(np.dot(self.weights, X_test.to_numpy()[i]))\n",
    "            y_predicted = np.append(y_predicted, y_predicted_value)\n",
    "            \n",
    "        return y_predicted\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test SVM class\n",
    "data = pd.read_csv('data/datasets_180_408_data.csv')\n",
    "\n",
    "# edit data\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': -1})\n",
    "data = data.drop(columns = ['id', 'Unnamed: 32'], axis=1)\n",
    "\n",
    "# assign independent and dependent variable\n",
    "X = data.iloc[:, 1:]\n",
    "Y = data.loc[:, 'diagnosis']\n",
    "\n",
    "X = pd.DataFrame(MinMaxScaler().fit_transform(X.values))\n",
    "X.insert(loc=len(X.columns), column='intercept', value=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM().fit(X_train.to_numpy(), y_train.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
